## GenAI

learning and implementing generative AI tools


## Literature

### Foundation

LLM Fine-tuning:

1. Ziegler, Daniel M., Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. "Fine-tuning language models from human preferences." arXiv preprint arXiv:1909.08593 (2019). [paper](https://arxiv.org/abs/1909.08593)
2. Rafailov, Rafael, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. "Direct preference optimization: Your language model is secretly a reward model." arXiv preprint arXiv:2305.18290 (2023). [paper](https://arxiv.org/abs/2305.18290)
3. Christiano, Paul F., Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei. "Deep reinforcement learning from human preferences." Advances in neural information processing systems 30 (2017).[paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/d5e2c0adad503c91f91df240d0cd4e49-Paper.pdf)
4. Bai et al 2022. Constitutional AI: Harmlessness from AI Feedback [paper](https://arxiv.org/abs/2212.08073)

### Application Areas

1. EHR 
2. Clinical workflow, chart summarization.
3. Genomics
4. Informed Consent
5. Research Ethics related documents. 
   1. Mirza et al (2024) NEJM AI. Using ChatGPT to Facilitate Truly Informed Medical Consent. [paper](https://ai.nejm.org/doi/full/10.1056/AIcs2300145)

### Implementation

1. Tutorials
   1. Huggingface

